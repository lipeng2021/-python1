{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "模型构造.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZVwZersBOXShjnuIfEzeb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lipeng2021/-python1/blob/main/%E6%A8%A1%E5%9E%8B%E6%9E%84%E9%80%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hMqMS48TpDNP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,**kwargs):\n",
        "    super(MLP,self).__init__(**kwargs)\n",
        "    self.hidden = nn.Linear(784,256)\n",
        "    self.act = nn.ReLU()\n",
        "    self.output = nn.Linear(256,10)\n",
        "  def forward(self,x):\n",
        "    y = self.output(self.act(self.hidden(x)))\n",
        "    return y"
      ],
      "metadata": {
        "id": "qVDcjZFFrMFD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,784)\n",
        "net = MLP()\n",
        "print(net)\n",
        "net(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2OoPUOZr7q0",
        "outputId": "04584f65-f37f-4a22-ec3e-c248c8ac9305"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (act): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2782,  0.2191, -0.2027, -0.1833, -0.0266, -0.1501, -0.0025,  0.0933,\n",
              "          0.0979, -0.1029],\n",
              "        [ 0.4179,  0.1537, -0.1378, -0.1933,  0.0387, -0.1275,  0.0035,  0.0686,\n",
              "          0.2108, -0.0524]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class MySequential(nn.Module):\n",
        "  from collections import OrderedDict\n",
        "  def __init__(self,*args):\n",
        "    super(MySequential,self).__init__()\n",
        "    if len(args)==1 and isinstance(args[0],OrderedDict):\n",
        "      for key,module in args[0].items():\n",
        "        self.add_module(key,module)\n",
        "    else:\n",
        "      for idx,module in enumerate(args):\n",
        "        self.add_module(str(idx),module)\n",
        "  def forward(self,input):\n",
        "    for module in self._modules.values():\n",
        "      input = module(input)\n",
        "    return input"
      ],
      "metadata": {
        "id": "OZqPpM-dtrRC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(\n",
        "    nn.Linear(784,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10),\n",
        ")\n",
        "print(net)\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbOfXMG_vjGW",
        "outputId": "05fb665f-0797-4dee-b3a7-7e6a387d8bcb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MySequential(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1650,  0.1123, -0.0918, -0.1199,  0.0848, -0.0162, -0.2380,  0.0709,\n",
              "         -0.0514,  0.1964],\n",
              "        [-0.2359,  0.1676, -0.1905, -0.0381,  0.1168,  0.0494, -0.1824, -0.1149,\n",
              "         -0.1075,  0.1750]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = torch.nn.Sequential(\n",
        "    nn.Linear(784,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10), \n",
        ")\n",
        "print(net)\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79yiidPfwiLc",
        "outputId": "a10a94ad-d6c5-4078-e67a-1e644aaf6b74"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2910,  0.0973, -0.0355, -0.2241, -0.0249,  0.0337,  0.0232,  0.1273,\n",
              "          0.2002, -0.1346],\n",
              "        [-0.2665,  0.0984,  0.0193, -0.2858,  0.0639, -0.0281,  0.0538,  0.2797,\n",
              "          0.2202,  0.0750]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net1 = nn.ModuleList([nn.Linear(784,256),nn.ReLU()])\n",
        "net1.append(nn.Linear(256,10))\n",
        "print(net1)\n",
        "print(net1[1])"
      ],
      "metadata": {
        "id": "9sjNKeX_yB3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=nn.ModuleDict({\n",
        "    'hidden':nn.Linear(784,256),\n",
        "    'act':nn.ReLU(),\n",
        "})\n",
        "net['output'] = nn.Linear(256,10)\n",
        "print(net)\n",
        "print(net['hidden'])\n",
        "print(net.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YneXPZazbpw",
        "outputId": "fcf6e35f-3570-4946-c06e-4fe85212d297"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModuleDict(\n",
            "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (act): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "Linear(in_features=784, out_features=256, bias=True)\n",
            "Linear(in_features=256, out_features=10, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FancyMLP(nn.Module):\n",
        "  def __init__(self,**kwargs):\n",
        "    super(FancyMLP,self).__init__(**kwargs)\n",
        "    self.rand_weight = torch.rand((20,20),requires_grad=False)\n",
        "    self.linear = nn.Linear(20,20)\n",
        "  def forward(self,x):\n",
        "    x = self.linear(x)\n",
        "    x = nn.functional.relu(torch.mm(x,self.rand_weight)+1)\n",
        "    x = self.linear(x)\n",
        "    while x.norm().item()>1:\n",
        "      x /=2\n",
        "    if x.norm().item()<0.8:\n",
        "      x*=10\n",
        "    return x,x.sum()\n"
      ],
      "metadata": {
        "id": "LOkQ0jZF4Ey4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,20)\n",
        "net = FancyMLP()\n",
        "net(x)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bvPZicQ5feu",
        "outputId": "8fb319f5-e01a-43fb-d7e1-4c43870166f9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FancyMLP(\n",
            "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "  def __init__(self,**kwargs):\n",
        "    super(NestMLP,self).__init__(**kwargs)\n",
        "    self.net = nn.Sequential(nn.Linear(40,30),nn.ReLU())\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "net = nn.Sequential(NestMLP(),nn.Linear(30,20),FancyMLP())\n",
        "x = torch.rand(2,40)\n",
        "\n",
        "print(net)\n",
        "net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhOixriO6PVw",
        "outputId": "07b98d90-c051-49f9-ffa6-7544bdd1cc89"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): NestMLP(\n",
            "    (net): Sequential(\n",
            "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=30, out_features=20, bias=True)\n",
            "  (2): FancyMLP(\n",
            "    (linear): Linear(in_features=20, out_features=20, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.6740,  0.5847, -1.5395, -0.1208, -0.3700,  0.0590,  0.1122,  0.5159,\n",
              "          -0.3026,  1.2844,  0.5595, -0.0845,  1.6344,  0.3923, -1.3881, -0.1865,\n",
              "          -0.5994, -0.5453,  0.1299,  0.2003],\n",
              "         [-1.5554,  0.4698, -1.4552, -0.1188, -0.3590,  0.0773,  0.1139,  0.4525,\n",
              "          -0.2728,  1.1555,  0.5744, -0.0367,  1.5081,  0.4419, -1.2907, -0.2371,\n",
              "          -0.5950, -0.5715,  0.1381,  0.2344]], grad_fn=<MulBackward0>),\n",
              " tensor(-2.6643, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}
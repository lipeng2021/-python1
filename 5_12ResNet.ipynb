{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-12ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+q+ESzsSx2Fre+5jV9Pyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lipeng2021/-python1/blob/main/5_12ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QmVQQQ1cbRoa"
      },
      "outputs": [],
      "source": [
        "from torch.cuda import is_available\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "from IPython import display\n",
        "import time\n",
        "FILENAME = '/home/lp'\n",
        "device = torch.device('cuda'if torch.cuda.is_available()else 'cpu')\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,use_1x1conv=False,stride=1):\n",
        "    super(Residual,self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1,stride=stride),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1,stride=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "    )\n",
        "    if use_1x1conv:\n",
        "      self.conv_1x1 = nn.Conv2d(in_channels,out_channels,stride=stride,kernel_size=1)\n",
        "    else:\n",
        "      self.conv_1x1 = None\n",
        "    self.conv_end = nn.Sequential(\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    feature = self.conv(x)\n",
        "    if self.conv_1x1:\n",
        "      x = self.conv_1x1(x)\n",
        "    y = self.conv_end(feature+x)\n",
        "    return y"
      ],
      "metadata": {
        "id": "mGJMUH-RmnzW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3,3)\n",
        "x = torch.rand((4,3,6,6))\n",
        "print(blk(x).shape)\n",
        "blk=Residual(3,6,use_1x1conv=True,stride=2)\n",
        "blk(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOYTauERqqNQ",
        "outputId": "cc46af37-214f-4eec-d3c9-223640f0a654"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 6, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 6, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        ")"
      ],
      "metadata": {
        "id": "i2BDcEf5vI6X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(in_channels,out_channels,num_residuals,first_block=False):\n",
        "  if first_block:\n",
        "    assert in_channels==out_channels\n",
        "  blk = []\n",
        "  for i in range(num_residuals):\n",
        "    if i==0 and not first_block:    \n",
        "      blk.append(Residual(in_channels,out_channels,use_1x1conv=True,stride=2))\n",
        "    else:\n",
        "      blk.append(Residual(out_channels,out_channels))\n",
        "  return nn.Sequential(*blk)"
      ],
      "metadata": {
        "id": "B0jd6OR22Iu6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.add_module('resnet_block1',resnet_block(64,64,2,first_block=True))\n",
        "net.add_module('resnet_block2',resnet_block(64,128,2))\n",
        "net.add_module('resnet_block3',resnet_block(128,256,2))\n",
        "net.add_module('resnet_block4',resnet_block(256,512,2))"
      ],
      "metadata": {
        "id": "jc7NFaSY4cQ0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalAveragePool(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GlobalAveragePool,self).__init__()\n",
        "  def forward(self,x):\n",
        "    return F.avg_pool2d(x,kernel_size=x.size()[2:])"
      ],
      "metadata": {
        "id": "UnhYVVLL43Y0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlattenLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FlattenLayer,self).__init__()\n",
        "  def forward(self,x):\n",
        "    return x.view(x.shape[0],-1)"
      ],
      "metadata": {
        "id": "sQCla5nT6fQb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.add_module('GlobalAveragePool',GlobalAveragePool())\n",
        "net.add_module('FlattenLayer',FlattenLayer())\n",
        "net.add_module('Fullcollection',nn.Linear(512,10))"
      ],
      "metadata": {
        "id": "rAW2PIdA6ESi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,1,224,224)\n",
        "for name,blk in net.named_children():\n",
        "  x = blk(x)\n",
        "  print(name,x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kimyelR60kK",
        "outputId": "47d11a96-7f89-46dc-e5f9-b0fb2e78dbfb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([1, 64, 112, 112])\n",
            "1 torch.Size([1, 64, 112, 112])\n",
            "2 torch.Size([1, 64, 112, 112])\n",
            "3 torch.Size([1, 64, 56, 56])\n",
            "resnet_block1 torch.Size([1, 64, 56, 56])\n",
            "resnet_block2 torch.Size([1, 128, 28, 28])\n",
            "resnet_block3 torch.Size([1, 256, 14, 14])\n",
            "resnet_block4 torch.Size([1, 512, 7, 7])\n",
            "GlobalAveragePool torch.Size([1, 512, 1, 1])\n",
            "FlattenLayer torch.Size([1, 512])\n",
            "Fullcollection torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_fashion_mnist(batch_size,resize=None,root='/home/lp'):\n",
        "  trans = []\n",
        "  if resize:\n",
        "    trans.append(torchvision.transforms.Resize(size=resize))\n",
        "  trans.append(torchvision.transforms.ToTensor())\n",
        "  transform = torchvision.transforms.Compose(trans)\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(root=root,train=True,transform=transform,download=True)\n",
        "  mnist_test = torchvision.datasets.FashionMNIST(root=root,train=False,transform=transform,download=True)\n",
        "  train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "  test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "  return train_iter,test_iter\n",
        "\n",
        "batch_size = 256\n",
        "train_iter,test_iter = load_data_fashion_mnist(batch_size,resize=96)\n",
        "def evalucate_accuracy(data_iter,net,device):\n",
        "  acc_sum=0.0\n",
        "  n=0\n",
        "  with torch.no_grad():\n",
        "    for X,y in data_iter:\n",
        "     if isinstance(net,nn.Module):\n",
        "        net.eval()\n",
        "        acc_sum += (net(X.to(device)).argmax(dim=1)==y.to(device)).float().sum().cpu().item()\n",
        "        net.train()\n",
        "     else:\n",
        "      if ('is_training'in net.__code__.co_varnames):\n",
        "        acc_sum +=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
        "      else:\n",
        "        acc_sum +=(net(X).argmax(dim=1)==y).float().sum().item()\n",
        "     n +=y.shape[0]\n",
        "    return acc_sum/n\n",
        "def train_ch5(net,train_iter,test_iter,batch_size,device,optimizer,num_epochs):\n",
        "  loss = torch.nn.CrossEntropyLoss()\n",
        "  net.to(device)\n",
        "  print('train on',device)\n",
        "  batch_cout = 0 \n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc_sum = 0.0\n",
        "    n = 0\n",
        "    start = time.time()\n",
        "    for X,y in train_iter:\n",
        "      X=X.to(device)\n",
        "      y=y.to(device)\n",
        "      y_hat = net(X)\n",
        "      l = loss(y_hat,y)\n",
        "      optimizer.zero_grad()\n",
        "      l.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += l.cpu().item()\n",
        "      train_acc_sum += (net(X).argmax(dim=1)==y).float().sum().cpu().item()\n",
        "      n += y.shape[0]\n",
        "      batch_cout +=1\n",
        "      print(batch_cout,end=' ')\n",
        "    test_acc_sum = evalucate_accuracy(test_iter,net,device)\n",
        "    print('epoch:%d,loss:%.4f,train_acc:%.3f,test_acc:%.3f,time:%.1f'%(epoch+1,train_loss/batch_cout,train_acc_sum/n,test_acc_sum,time.time()-start))"
      ],
      "metadata": {
        "id": "sVDkkVv67jwo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr =0.001\n",
        "num_epochs =5\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n",
        "train_ch5(net,train_iter,test_iter,batch_size,device,optimizer,num_epochs)"
      ],
      "metadata": {
        "id": "8rjFK91I7wM_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}